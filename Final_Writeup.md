# Seattle House Price Predictor 

**Abstract:**

House prices in the Seattle area have steadily increased since 2008. With this steady increase it is difficult to predict the present value of a home. The goal of this project is to create a linear regression model that will predict the present value of a home based on key features of the home. The intent is to insure that buyers are not are not overpaying for a home and sellers are not under-valuing a home. House data was scraped from Realtor.com for the Seattle area and stored in a SQL database. After the data was cleaned a pipeline was created and a linear regression model was fit. In order to make this model useful to the consumer a Streamlit app was constructed that will take real time user input for house features, send that data to the trained pipeline and return a projected home value. To make the application widely available, the app was deployed on Heroku. 

The SQL database was originally constructed by scraping all available homes in the Seattle area on Realtor.com. After the initial pull, data was scraped on a daily basis to grow the dataset. The dataset currently contains 1,730 homes in the Seattle area from 30 distinct zip codes. There are a total of five features excluding the target variable price. Those features are, number of beds, baths, size of house, size of lot, and zip code. The zip code was considered to be a categorical variable and encoded to not corrupt the linear regression model. Apartments usually do not have a lot size specified. The assumption was made that if lot size does not exist then lot size will be set equal to size of home. Additionally, studio apartments were given a bedroom count of zero. 

Initially pyspark was used for the entire data pipeline to become more familiar with pyspark syntax. After the pipeline was constructed and a local application was built it was determined that a multi-node system like pyspark would not be able to easily be deployed on Heroku or Streamlit Share. After this fact was learned the data pipeline was reconstructed using the Scikit Learn machine learning package. A basic linear regression model was trained on the data and an r-squared value of 71.6% was obtained on the test data. A mean absolute error of roughly $260,000 was achieved. After the results were analyzed, it was found that the data was right skewed. There are a number of outlier houses that fall above the two million dollar range that seems to be throwing the model off.

After the pipeline was constructed it was imported into a new python script where a Streamlit application was constructed. The Streamlit app has a drop down menu for the user to pick the zip code of a house to ensure that the zip code is not outside the Seattle area. Other user inputs include number of beds, baths, house size and lot size. These values are passed into a labeled pandas dataframe, passed into the machine learning pipeline and a predicted house price is output to the user. The Streamlit app was first constructed locally, then deployed on both Streamlit Share and Heroku using different Github repositories to house the models and scripts. 

The intent of this project was to build an end to end data pipeline with a user facing application. The quality of the data and the accuracy of the machine learning model was not the highest priority. In future iterations of this project a different data source would be scrapped (Compass.com). Realtor.com has many scrapping blockers in place making it difficult to navigate to each individual property page without getting blocked. The individual pages contain much more detailed information about each house that could be used as new features in the dataset. Additionally, a larger number of regression models would be trained and model parameters would be tuned to increase the overall accuracy of the final model. Outliers could be removed from the dataset to reduce the right skewness and increase overall performance on average consumer homes. 
